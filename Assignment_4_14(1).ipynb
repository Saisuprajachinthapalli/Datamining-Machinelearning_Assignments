{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKQh3krioX9l",
        "outputId": "c67e059b-d687-4afe-ae12-d9c01ccd8538"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Y_train shape after to_categorical: (50000, 10)\n",
            "Y_test shape after to_categorical: (10000, 10)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "# Creating a list of all the class labels\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "# Converting the pixels data to float type\n",
        "train_images = train_images.astype('float32')\n",
        "test_images = test_images.astype('float32')\n",
        "\n",
        "# Normalize input\n",
        "train_images = train_images / 255\n",
        "test_images = test_images / 255\n",
        "\n",
        "# change target class to one hot encoding\n",
        "# use ‘to_categorical’ function\n",
        "\n",
        "num_classes = 10\n",
        "Y_train = to_categorical(train_labels, num_classes)\n",
        "Y_test = to_categorical(test_labels, num_classes)\n",
        "\n",
        "# Check the resulting shapes\n",
        "print(\"Y_train shape after to_categorical:\", Y_train.shape)\n",
        "print(\"Y_test shape after to_categorical:\", Y_test.shape)\n",
        "\n",
        "\n",
        "# Change target class to one hot encoding using 'to_categorical' function\n",
        "train_labels = to_categorical(train_labels, num_classes)\n",
        "test_labels = to_categorical(test_labels, num_classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=train_images\n",
        "X_test=test_images\n",
        "\n",
        "\n",
        "# Show the shape of the datasets\n",
        "\n",
        "print(\"Shape of train_images:\", X_train.shape)\n",
        "print(\"Shape of train_labels:\", Y_train.shape)\n",
        "print(\"Shape of test_images:\", X_test.shape)\n",
        "print(\"Shape of test_labels:\", Y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6eNee-EStCqf",
        "outputId": "5dc4803f-9a52-43cc-b453-d1bed0cb73f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of train_images: (50000, 32, 32, 3)\n",
            "Shape of train_labels: (50000, 10)\n",
            "Shape of test_images: (10000, 32, 32, 3)\n",
            "Shape of test_labels: (10000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "def create_model(input_shape, fine_tune=0):\n",
        "    # Load the VGG16 model with pretrained weights, excluding the top layers\n",
        "    conv_base = VGG16(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
        "\n",
        "    # Freeze layers according to the fine_tune parameter\n",
        "    if fine_tune > 0:\n",
        "        for layer in conv_base.layers[:-fine_tune]:\n",
        "            layer.trainable = False\n",
        "    else:\n",
        "        for layer in conv_base.layers:\n",
        "            layer.trainable = False\n",
        "\n",
        "    # Build the model with resizing, convolutional base, and fully connected layers\n",
        "    model = models.Sequential([\n",
        "        layers.Resizing(224, 224, interpolation=\"bilinear\", input_shape=input_shape),  # Resizing layer\n",
        "        conv_base,\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),  # First dense layer with 128 nodes\n",
        "        layers.Dense(64, activation='relu'),   # Second dense layer with 64 nodes\n",
        "        layers.Dense(10, activation='softmax')  # Output layer for 10 classes\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "PwlgjBSLtZhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = X_train[0].shape\n",
        "model = create_model(input_shape, fine_tune=0)\n",
        "print(model.summary())\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, Y_train,\n",
        "                    epochs=1,\n",
        "                    batch_size=64,\n",
        "                    validation_data=(X_test, Y_test))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test, Y_test, verbose=2)\n",
        "\n",
        "# Print test accuracy\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "\n",
        "# Plot accuracy and loss\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Test Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Test Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "H-nAe5ZTwgRu",
        "outputId": "eaa86cac-f411-4cd2-a0d1-8b1971167c52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ resizing (\u001b[38;5;33mResizing\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ vgg16 (\u001b[38;5;33mFunctional\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │      \u001b[38;5;34m14,714,688\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25088\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │       \u001b[38;5;34m3,211,392\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m650\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ resizing (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Resizing</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ vgg16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25088</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,211,392</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m17,934,986\u001b[0m (68.42 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,934,986</span> (68.42 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,220,298\u001b[0m (12.28 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,220,298</span> (12.28 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m14,714,688\u001b[0m (56.13 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> (56.13 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "\u001b[1m 12/782\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:12:14\u001b[0m 43s/step - accuracy: 0.1002 - loss: 2.6975"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_with_fine_tune_layers(num_trainable_layers, input_shape):\n",
        "    # Create the model with a specific number of layers trainable\n",
        "    model = create_model(input_shape, fine_tune=num_trainable_layers)\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(\n",
        "        X_train, Y_train,\n",
        "        epochs=10,  # You can adjust the epochs based on training time\n",
        "        batch_size=64,\n",
        "        validation_data=(X_test, Y_test),\n",
        "        verbose=0  # Set to 0 to suppress detailed output\n",
        "    )\n",
        "\n",
        "    # Get the final validation accuracy for the model\n",
        "    final_val_accuracy = history.history['val_accuracy'][-1]\n",
        "    return final_val_accuracy\n",
        "\n",
        "# Define input shape and number of layers to try\n",
        "input_shape = X_train[0].shape\n",
        "trainable_layers_range = range(0, len(VGG16(include_top=False).layers) + 1, 5)  # Adjust step size as needed\n",
        "accuracies = []\n",
        "\n",
        "for layers in trainable_layers_range:\n",
        "    print(f\"Training with {layers} trainable layers...\")\n",
        "    accuracy = train_with_fine_tune_layers(layers, input_shape)\n",
        "    accuracies.append(accuracy)\n",
        "    print(f\"Validation Accuracy with {layers} trainable layers: {accuracy:.4f}\")\n",
        "\n",
        "plt.plot(trainable_layers_range, accuracies, marker='o')\n",
        "plt.xlabel('Number of Trainable Layers')\n",
        "plt.ylabel('Validation Accuracy')\n",
        "plt.title('Validation Accuracy vs. Number of Trainable Layers')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Find the optimal number of layers\n",
        "optimal_layers = trainable_layers_range[accuracies.index(max(accuracies))]\n",
        "print(f\"Optimal number of trainable layers: {optimal_layers}\")\n"
      ],
      "metadata": {
        "id": "Q0rITe272hn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import datasets\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
        "\n",
        "# Reshape to (num_samples, 28, 28, 1) and then resize to (224, 224, 3)\n",
        "train_images = np.expand_dims(train_images, axis=-1)  # Add channel dimension (grayscale)\n",
        "test_images = np.expand_dims(test_images, axis=-1)\n",
        "\n",
        "# Resize the images to 224x224 and convert grayscale to 3 channels\n",
        "train_images_resized = np.array([tf.image.resize(img, (224, 224)) for img in train_images])\n",
        "test_images_resized = np.array([tf.image.resize(img, (224, 224)) for img in test_images])\n",
        "\n",
        "# Convert grayscale to 3 channels (RGB)\n",
        "train_images_resized = np.repeat(train_images_resized, 3, axis=-1)\n",
        "test_images_resized = np.repeat(test_images_resized, 3, axis=-1)\n",
        "\n",
        "# Normalize the images\n",
        "train_images_resized = train_images_resized.astype('float32') / 255\n",
        "test_images_resized = test_images_resized.astype('float32') / 255\n",
        "\n",
        "# One-hot encode the labels\n",
        "num_classes = 10\n",
        "train_labels_one_hot = to_categorical(train_labels, num_classes)\n",
        "test_labels_one_hot = to_categorical(test_labels, num_classes)\n",
        "\n",
        "# Check the shapes\n",
        "print(\"Shape of train_images_resized:\", train_images_resized.shape)\n",
        "print(\"Shape of test_images_resized:\", test_images_resized.shape)\n",
        "print(\"Shape of train_labels_one_hot:\", train_labels_one_hot.shape)\n",
        "print(\"Shape of test_labels_one_hot:\", test_labels_one_hot.shape)\n",
        "\n",
        "# Use the same function for training the model with varying trainable layers\n",
        "def train_with_fine_tune_layers_mnist(num_trainable_layers, input_shape):\n",
        "    # Create the model with a specific number of layers trainable\n",
        "    model = create_model(input_shape, fine_tune=num_trainable_layers)\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(\n",
        "        train_images_resized, train_labels_one_hot,\n",
        "        epochs=1,  # You can adjust the epochs based on training time\n",
        "        batch_size=64,\n",
        "        validation_data=(test_images_resized, test_labels_one_hot),\n",
        "        verbose=0  # Set to 0 to suppress detailed output\n",
        "    )\n",
        "\n",
        "    # Get the final validation accuracy for the model\n",
        "    final_val_accuracy = history.history['val_accuracy'][-1]\n",
        "    return final_val_accuracy\n",
        "\n",
        "# Define input shape for MNIST\n",
        "input_shape_mnist = train_images_resized[0].shape\n",
        "trainable_layers_range = range(0, len(VGG16(include_top=False).layers) + 1, 5)  # Adjust step size as needed\n",
        "accuracies_mnist = []\n",
        "\n",
        "# Train with varying number of trainable layers\n",
        "for layers in trainable_layers_range:\n",
        "    print(f\"Training with {layers} trainable layers...\")\n",
        "    accuracy = train_with_fine_tune_layers_mnist(layers, input_shape_mnist)\n",
        "    accuracies_mnist.append(accuracy)\n",
        "    print(f\"Validation Accuracy with {layers} trainable layers: {accuracy:.4f}\")\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(trainable_layers_range, accuracies_mnist, marker='o')\n",
        "plt.xlabel('Number of Trainable Layers')\n",
        "plt.ylabel('Validation Accuracy')\n",
        "plt.title('Validation Accuracy vs. Number of Trainable Layers (MNIST)')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Find the optimal number of layers\n",
        "optimal_layers_mnist = trainable_layers_range[accuracies_mnist.index(max(accuracies_mnist))]\n",
        "print(f\"Optimal number of trainable layers for MNIST: {optimal_layers_mnist}\")\n"
      ],
      "metadata": {
        "id": "9TQWduNQ3Qol"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}